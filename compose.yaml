
x-airflow-common:
  &airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
  # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.10.3}
  build:
    context: ${AIRFLOW_DIR:-.}
    dockerfile: Dockerfile
  profiles: 
    - airflow
    - all
  networks:
    - shared-network
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres_admin:postgres_admin@postgresql/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres_admin:postgres_admin@postgresql/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: 'uEd8hPxlloymZYOkxfhcldeB4W-QZqf_Dv-1PW2d1EQ='
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    # AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    # yamllint disable rule:line-length
    # Use simple http server on scheduler for health checks
    # See https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html#scheduler-health-check-server
    # yamllint enable rule:line-length
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
    # for other purpose (development, test and especially production usage) build/extend Airflow image.
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    # The following line can be used to set a custom config file, stored in the local config folder
    # If you want to use it, outcomment it and replace airflow.cfg with the name of your config file
    AIRFLOW_CONFIG: '/opt/airflow/config/airflow.cfg'
    AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
    AIRFLOW__SMTP__SMTP_STARTTLS: False
    AIRFLOW__SMTP__SMTP_SSL: True
    AIRFLOW__SMTP__SMTP_USER: "<YOUR_SMTP_USER>" 
    # Example: AIRFLOW__SMTP__SMTP_USER: "example@gmail.com"
    AIRFLOW__SMTP__SMTP_PASSWORD: "<YOUR_SMTP_PASSWORD>"
    AIRFLOW__SMTP__SMTP_PORT: 465
    AIRFLOW__EMAIL__FROM_EMAIL: "<YOUR_SMTP_EMAIL>"
    # Example: AIRFLOW__EMAIL__FROM_EMAIL: "example@gmail.com"
    X-RAPID-API-KEY: "<YOUR_RAPID_API_KEY>"
    GROQ-API-KEY: "<YOUR_GROQ_API_KEY>"
    KAFKA_BOOTSTRAP_SREVERS: kafka1:19092,kafka2:19093
    SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081
  volumes:
    - ${AIRFLOW_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_DIR:-.}/config:/opt/airflow/config
    - ${AIRFLOW_DIR:-.}/plugins:/opt/airflow/plugins
    - ${ETL_DIR:-.}/config:/opt/airflow/etl-config
    - ${ETL_DIR:-.}/scripts:/opt/airflow/etl-scripts
    - ${ETL_DIR:-.}/spark-jobs:/opt/airflow/etl-spark-jobs
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy


x-spark-common: &spark-common
  image: bitnami/spark:3.5.2-debian-12-r0
  profiles: 
    - spark
    - all
  volumes:
    - ${SPARK_DIR:-.}/config/log4j2.properties:/opt/bitnami/spark/conf/log4j2.properties
    - ${SPARK_DIR:-.}/logs:/opt/bitnami/spark/logs
    - ${ETL_DIR:-.}/spark-jobs:/opt/bitnami/spark/jobs
  networks:
    - shared-network


x-kafka-common: &kafka-common
  profiles: 
    - kafka
    - all
  networks:
    - shared-network
  volumes:
    - ${JMXEXPORTER_DIR:-.}:/usr/share/jmx_exporter/


x-monitor-common: &monitor-common
  profiles: 
    - monitor
    - all
  networks:
    - shared-network


services:

  postgres:
    image: postgres:14
    hostname: postgresql
    container_name: postgresql
    profiles:
      - airflow
      - conduktor
      - all
      - post
    networks:
      - shared-network
    environment:
      POSTGRES_USER: postgres_admin
      POSTGRES_PASSWORD: postgres_admin
      POSTGRES_MULTIPLE_DATABASES: conduktor,airflow
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ${DB_DIR:-.}/multiple-databases.sh:/docker-entrypoint-initdb.d/multiple-databases.sh
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "$$POSTGRES_USER"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always


  redis:
    # Redis is limited to 7.2-bookworm due to licencing change
    # https://redis.io/blog/redis-adopts-dual-source-available-licensing/
    image: redis:7.2-bookworm
    container_name: airflow_redis
    profiles:
      - airflow
      - all
    hostname: redis
    expose:
      - 6379
    networks:
      - shared-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always


  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    command: webserver
    ports:
      - "8086:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-worker-1:
    <<: *airflow-common
    container_name: airflow_worker_1
    command: celery worker
    healthcheck:
      # yamllint disable rule:line-length
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-worker-2:
    <<: *airflow-common
    container_name: airflow_worker_2
    command: celery worker
    healthcheck:
      # yamllint disable rule:line-length
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-triggerer:
    <<: *airflow-common
    container_name: airflow_triggerer
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo "For other operating systems you can get rid of the warning with manually created .env file:"
          echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
          echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
          echo
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
          echo "At least 2 CPUs recommended. You have $${cpus_available}"
          echo
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
          echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
          echo
          warning_resources="true"
        fi
        if [[ $${warning_resources} == "true" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
          echo "Please follow the instructions to increase amount of resources available:"
          echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow_admin}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow_admin}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: "0:0"
    volumes:
      - ${AIRFLOW_DIR:-.}:/sources


  airflow-cli:
    <<: *airflow-common
    container_name: airflow_cli
    # profiles:
    #   - debug
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: "0"
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    entrypoint: [ ]
    command:
      # - bash
      # - -c
      # - airflow
      - sleep
      - infinity


  flower:
    <<: *airflow-common
    container_name: flower
    profiles:
      - monitor 
      - all
    ports:
      - "5555:5555"
    command: celery flower
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully


  spark-master:
    <<: *spark-common
    container_name: spark-master
    ports:
      - "8084:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    

  spark-worker-1:
    <<: *spark-common
    container_name: spark_worker_1
    ports:
      - "8085:8080"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark


  spark-worker-2:
    <<: *spark-common
    container_name: spark_worker_2
    ports:
      - "8087:8080"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark


  zoo1:
    <<: *kafka-common
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo1
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888
      EXTRA_ARGS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/zookeeper.yml


  zoo2:
    <<: *kafka-common
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zoo2
    container_name: zoo2
    ports:
      - "2182:2182"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888
      EXTRA_ARGS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/zookeeper.yml


  kafka1:
    <<: *kafka-common
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      # KAFKA_OPTS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/kafka-broker.yml
      EXTRA_ARGS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/kafka-broker.yml
      # KAFKA_JMX_OPTS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/kafka-broker.yml
    depends_on:
      - zoo1
      - zoo2


  kafka2:
    <<: *kafka-common
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182"
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      EXTRA_ARGS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/kafka-broker.yml
    depends_on:
      - zoo1
      - zoo2


  kafka-init:
    <<: *kafka-common
    build:
      context: ${KAFKA_DIR:-.}
      dockerfile: Dockerfile.init
    container_name: kafka-init
    depends_on:
      kafka1:
        condition: service_started
      kafka2:
        condition: service_started
      kafka-schema-registry:
        condition: service_started
      kafka-connect:
        condition: service_healthy
    volumes:
      - ${KAFKA_DIR:-.}/schemas:/schemas
      - ${KAFKA_DIR:-.}/scripts:/scripts
      - ${KAFKA_DIR:-.}/config:/config
    entrypoint:
      - /bin/bash
      - -c
      - |
        chmod +x /scripts/init.sh
        /scripts/init.sh /schemas
    restart: "no"  


  kafka-schema-registry:
    <<: *kafka-common
    image: confluentinc/cp-schema-registry:7.3.2
    hostname: kafka-schema-registry
    container_name: kafka-schema-registry
    depends_on:
      - zoo1
      - zoo2
      - kafka1
      - kafka2
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:19092,PLAINTEXT://kafka2:19093
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_JMX_OPTS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/confluent_schemaregistry.yml   
    restart: on-failure


  kafka-rest-proxy:
    <<: *kafka-common
    image: confluentinc/cp-kafka-rest:7.3.2
    hostname: kafka-rest-proxy
    container_name: kafka-rest-proxy
    ports:
      - "8082:8082"
    environment:
      # KAFKA_REST_ZOOKEEPER_CONNECT: zoo1:2181
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082/
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081/
      KAFKA_REST_HOST_NAME: kafka-rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1:19092,PLAINTEXT://kafka2:19093'
    depends_on:
      - zoo1
      - zoo2
      - kafka1
      - kafka2
      - kafka-schema-registry


  kafka-connect:
    <<: *kafka-common
    image: confluentinc/cp-kafka-connect:7.3.2
    hostname: kafka-connect
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka1:19092,kafka2:19093"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars,/usr/share/confluent-hub-components'
      CONNECT_BIGQUERY_KEYFILE: "/etc/kafka-connect/keyfile.json"
      CONNECT_BIGQUERY_PROJECT: "your-gcp-project-id"
      CONNECT_BIGQUERY_DATASETS: "test_topic:bq_kafka_dataset"
      KAFKA_JMX_OPTS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.20.0.jar=9200:/usr/share/jmx_exporter/kafka-connect.yml
    volumes:
      - ${KAFKA_DIR:-.}/connectors:/etc/kafka-connect/jars/
      - ${KAFKA_DIR:-.}/config/keyfile.json:/etc/kafka-connect/keyfile.json
      - ${KAFKA_DIR:-.}/config/bigquery-sink.json:/etc/kafka-connect/bigquery-sink.json
      - ${JMXEXPORTER_DIR:-.}:/usr/share/jmx_exporter/
    depends_on:
      - zoo1
      - zoo2
      - kafka1
      - kafka2
      - kafka-schema-registry
      - kafka-rest-proxy
    command:
      - bash
      - -c
      - |
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:latest
        confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:0.4.0
        confluent-hub install --no-prompt wepay/kafka-connect-bigquery:2.2.0
        /etc/confluent/docker/run

  
  # ksqldb-server:
  #   image: confluentinc/cp-ksqldb-server:7.3.2
  #   profiles: 
  #     - monitor
  #     - all
  #   hostname: ksqldb-server
  #   container_name: ksqldb-server
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     KSQL_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1:19092,PLAINTEXT://kafka2:19093'
  #     KSQL_LISTENERS: http://0.0.0.0:8088/
  #     KSQL_KSQL_SERVICE_ID: ksqldb-server_
  #   depends_on:
  #     - zoo1
  #     - kafka1


  prometheus:
    <<: *monitor-common
    image: prom/prometheus:v2.47.2
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ${PROMETHEUS_DIR:-.}:/etc/prometheus


  # alertmanager:
  #   <<: *monitor-common
  #   image: prom/alertmanager:v0.26.0
  #   container_name: alertmanager
  #   ports:
  #     - "19093:9093"


  # conduktor-console:
  #   <<: *monitor-common
  #   image: conduktor/conduktor-console:1.26.0
  #   hostname: conduktor-console
  #   container_name: conduktor-console
  #   ports:
  #     - "8080:8080"
  #   environment:
  #     CDK_DATABASE_URL: "postgresql://postgres_admin:postgres_admin@postgresql:5432/conduktor-console"
  #     CDK_CLUSTERS_0_ID: "default"
  #     CDK_CLUSTERS_0_NAME: "My Local Kafka Cluster"
  #     CDK_CLUSTERS_0_COLOR: "#0013E7"
  #     CDK_CLUSTERS_0_BOOTSTRAPSERVERS: "PLAINTEXT://kafka1:19092,PLAINTEXT://kafka2:19093"
  #     CDK_CLUSTERS_0_SCHEMAREGISTRY_URL: "http://kafka-schema-registry:8081"
  #     CDK_CLUSTERS_0_KAFKACONNECTS_0_URL: "http://kafka-connect:8083"
  #     CDK_CLUSTERS_0_KAFKACONNECTS_0_NAME: "full stack kafka connect"
  #   volumes:
  #     - conduktor_data:/var/conduktor
  #   depends_on:
  #     - postgres


  grafana:
    <<: *monitor-common
    image: grafana/grafana:5.2.1
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ${MONITORING_DIR:-.}/grafana/provisioning:/etc/grafana/provisioning
      

volumes:
  pg_data: 
    name: pg_data
  grafana_data: 
    name: grafana_data
  conduktor_data: 
    name: conduktor_data

networks:
  shared-network:
    name: de-network
    driver: bridge